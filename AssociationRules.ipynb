{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from apyori import apriori\n",
    "from statistics import mean,stdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read the transaction data and subset for transactions in Idaho\n",
    "chunks = pd.read_csv(\"DillardsPOS/newTrans.csv\", chunksize=10**6)\n",
    "\n",
    "dat_chunks = []\n",
    "for chunk in chunks:\n",
    "    mask = (chunk['store']==3409) | (chunk['store']==3609) | (chunk['store']==3509)\n",
    "    dat_chunks.append(chunk.loc[mask])\n",
    "\n",
    "trnsDF = pd.concat(dat_chunks,axis = 0)\n",
    "trnsDF = trnsDF[trnsDF.type=='P']\n",
    "trnsDF.drop(columns = ['type'], inplace = True)\n",
    "del dat_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset dataframe by storesID \n",
    "ID1 = trnsDF[trnsDF.store == 3409]\n",
    "ID2 = trnsDF[trnsDF.store == 3509]\n",
    "ID3 = trnsDF[trnsDF.store == 3609]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format list for apriori\n",
    "S1 = ID1.groupby(['reg','trans','date'])['sku'].transform(lambda x: ','.join(map(str,x))).to_frame('itemList')\n",
    "S2 = ID2.groupby(['reg','trans','date'])['sku'].transform(lambda x: ','.join(map(str,x))).to_frame('itemList')\n",
    "S3 = ID3.groupby(['reg','trans','date'])['sku'].transform(lambda x: ','.join(map(str,x))).to_frame('itemList')\n",
    "\n",
    "S1 = S1.reset_index(drop = True)\n",
    "S2 = S2.reset_index(drop = True)\n",
    "S2 = S2.reset_index(drop = True)\n",
    "\n",
    "S1 = S1['itemList'].str.split(',')\n",
    "S2 = S2['itemList'].str.split(',')\n",
    "S3 = S3['itemList'].str.split(',')\n",
    "\n",
    "itemLists1 = []\n",
    "itemLists2 = []\n",
    "itemLists3 = []\n",
    "\n",
    "for i in range(len(S1)):\n",
    "    itemLists1.append(S1[i])\n",
    "    \n",
    "for j in range(len(S2)):\n",
    "    itemLists2.append(S2[j])\n",
    "    \n",
    "for k in range(len(S3)):\n",
    "    itemLists3.append(S3[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Store 3409 has 113768 unique sku\n",
      "Store 3509 has 51030 unique sku\n",
      "Store 3609 has 64077 unique sku\n",
      "\n",
      "\n",
      "Store 3409 has avg 3.1436352309472246 items/basket\n",
      "Store 3509 has avg 3.5852746877717014 items/basket\n",
      "Store 3609 has avg 3.3766724391177867 items/basket\n"
     ]
    }
   ],
   "source": [
    "# Data Exploration\n",
    "\n",
    "# Determine number of unique sku's\n",
    "stores = [3409, 3509, 3609]\n",
    "IDs = [ID1,ID2,ID3]\n",
    "uCount = []\n",
    "for i in range(3):\n",
    "    uCount.append(IDs[i]['sku'].nunique())\n",
    "\n",
    "for i in range(3):\n",
    "    p = f'Store {stores[i]} has {uCount[i]} unique sku'\n",
    "    print(p)\n",
    "    \n",
    "# Determine average items/basket\n",
    "aItems = [[],[],[]]\n",
    "\n",
    "for i in range(len(itemLists1)):\n",
    "    aItems[0].append(len(itemLists1[i]))\n",
    "\n",
    "for i in range(len(itemLists2)):\n",
    "    aItems[1].append(len(itemLists2[i]))\n",
    "\n",
    "for i in range(len(itemLists3)):\n",
    "    aItems[2].append(len(itemLists3[i]))\n",
    "\n",
    "print('\\n')\n",
    "for i in range(3):\n",
    "    p = f'Store {stores[i]} has avg {mean(aItems[i])} items/basket'\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run apriori\n",
    "aRules1 = apriori(itemLists1,min_support=.0005,min_confidence=.02, min_lift=3,min_length=2)\n",
    "aResults1 = list(aRules1)\n",
    "\n",
    "aRules2 = apriori(itemLists2,min_support=.0005,min_confidence=.02, min_lift=3,min_length=2)\n",
    "aResults2 = list(aRules2)\n",
    "\n",
    "aRules3 = apriori(itemLists3,min_support=.0005,min_confidence=.02, min_lift=3,min_length=2)\n",
    "aResults3 = list(aRules3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interpretable dataframe\n",
    "header={'store':[],'antecedent':[],'consequent':[],'lift':[]}\n",
    "finalDF = pd.DataFrame(header)\n",
    "\n",
    "for item in aResults1:\n",
    "    pair = item[0] \n",
    "    items = [x for x in pair]\n",
    "    newRow = pd.DataFrame({'store':[3409],'antecedent':[items[0]],'consequent':[items[1]],'lift':[item[2][0][3]]})\n",
    "    finalDF = finalDF.append(newRow)\n",
    "\n",
    "for item in aResults2:\n",
    "    pair = item[0] \n",
    "    items = [x for x in pair]\n",
    "    newRow = pd.DataFrame({'store':[3509],'antecedent':[items[0]],'consequent':[items[1]],'lift':[item[2][0][3]]})\n",
    "    finalDF = finalDF.append(newRow)\n",
    "\n",
    "for item in aResults3:\n",
    "    pair = item[0] \n",
    "    items = [x for x in pair]\n",
    "    newRow = pd.DataFrame({'store':[3609],'antecedent':[items[0]],'consequent':[items[1]],'lift':[item[2][0][3]]})\n",
    "    finalDF = finalDF.append(newRow)\n",
    "    \n",
    "finalDF.sort_values('lift',ascending = False,inplace=True)\n",
    "finalDF = finalDF.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary statistics by Lift\n",
      "        lift                                                            \n",
      "       count         mean         std       min         50%          max\n",
      "store                                                                   \n",
      "3409    28.0    23.225808   23.968440  5.033627    8.539068    83.212486\n",
      "3509   366.0  1134.649650  414.147775  9.673013  984.536000  1984.951613\n",
      "3609    45.0   690.899841  556.276117  9.245482  851.845180  1605.220183\n",
      "\n",
      " Summary statistics for top 100 rules ranked by Lift\n",
      "       lift                                                               \n",
      "      count         mean        std          min          50%          max\n",
      "store                                                                     \n",
      "3509   99.0  1642.490263  62.205883  1598.272727  1640.893333  1984.951613\n",
      "3609    1.0  1605.220183        NaN  1605.220183  1605.220183  1605.220183\n"
     ]
    }
   ],
   "source": [
    "# Interpret results\n",
    "print('Summary statistics by Lift')\n",
    "grp1 = finalDF.groupby('store')\n",
    "print(grp1.describe(percentiles=[]))\n",
    "\n",
    "print('\\n Summary statistics for top 100 rules ranked by Lift')\n",
    "grp2 = finalDF[0:100].groupby('store')\n",
    "print(grp2.describe(percentiles=[]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary statistics for unique rules\n",
      "        lift                                                              \n",
      "       count         mean         std        min          50%          max\n",
      "store                                                                     \n",
      "3409.0   4.0    23.023933   29.202014   7.771379     8.756059    66.812236\n",
      "3509.0  57.0  1171.531087  481.213519  14.828266  1274.289924  1984.951613\n",
      "3609.0  24.0   798.944492  530.213599   9.768457  1008.725759  1567.254529\n"
     ]
    }
   ],
   "source": [
    "newDF = pd.DataFrame(header)\n",
    "SKU = []\n",
    "\n",
    "for i in range(len(finalDF)):\n",
    "    if (finalDF.consequent[i] not in SKU):\n",
    "        newDF = newDF.append(finalDF.iloc[i])\n",
    "        SKU.append(finalDF.antecedent[i])\n",
    "        SKU.append(finalDF.consequent[i])\n",
    "\n",
    "print('Summary statistics for unique rules')\n",
    "newDF = newDF.reset_index(drop = True)\n",
    "grp3 = newDF.groupby('store')\n",
    "print(grp3.describe(percentiles=[]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalDF.to_csv(\"rulesRanked.csv\")\n",
    "newDF.to_csv(\"rulesRankedUnique.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
